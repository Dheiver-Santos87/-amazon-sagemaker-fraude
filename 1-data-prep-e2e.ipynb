{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecção de Fraude em contratos de seguros: Preparação de Dados, Processo e Recursos de Armazenamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Este notebook é a segunda parte de uma série de notebooks que demonstrarão como preparar, treinar e implantar um modelo que detecta reclamações automáticas fraudulentas. Neste notebook, estaremos preparando, processando e armazenando recursos usando o SageMaker Feature Store. Você pode optar por executar este notebook sozinho ou em sequência com os outros notebooks listados abaixo. Consulte o [README.md](README.md) para obter mais informações sobre este caso de uso implementado por esta série de notebooks.\n",
    "\n",
    "1. **[Detecção de Fraude em contratos de seguros: exploração de dados](./0-AutoClaimFraudDetection.ipynb)**\n",
    "1. [Detecção de Fraude em contratos de seguros: preparação de dados, processo e recursos de armazenamento](./1-data-prep-e2e.ipynb)\n",
    "1. [Detecção de Fraude em contratos de seguros: treinar, verificar viés, ajustar, registrar linhagem e registrar um modelo](./2-lineage-train-assess-bias-tune-registry-e2e.ipynb)\n",
    "1. [Detecção de Fraude em contratos de seguros: mitigar, treinar, registrar e implantar modelo imparcial](./3-mitigate-bias-train-model2-registry-e2e.ipynb)\n",
    "\n",
    "\n",
    "## Conteúdo\n",
    "1. [Arquitetura para preparação de dados, recursos e armazenamento](#Arquitetura para preparação de dados, recursos de processo e armazenamento)\n",
    "1. [Introdução: Criando recursos](#Getting-Started:-Creating-Resources)\n",
    "1. [Conjuntos de dados e tipos de recursos](#Datasets-and-Feature-Types)\n",
    "1. [SageMaker Feature Store](#SageMaker-Feature-Store)\n",
    "1. [Criar conjuntos de dados de treinamento e teste](#Create-Train-and-Test-Datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo deste notebook é realizar a fase de preparação de dados do ciclo de vida de ML. O principal Data Wrangling, ingestão de dados e várias transformações serão feitos por meio da GUI do Data Wrangler do SageMaker Studio.\n",
    "\n",
    "Neste notebook, pegaremos os arquivos `.flow` que definem as transformações para os dados brutos. e aplique-os usando um trabalho de processamento do SageMaker que aplicará essas transformações aos dados brutos depositados no bucket do S3 como arquivos `.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquitetura para preparação dos recursos, processo e armazenamento de dados\n",
    "----\n",
    "![Data Prep and Store](./images/e2e-1-pipeline-v3b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required and/or update third-party libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda 4.13.0 requires ruamel_yaml_conda>=0.11.14, which is not installed.\n",
      "pyathena 2.13.0 requires boto3>=1.21.0, but you have boto3 1.17.70 which is incompatible.\n",
      "pyathena 2.13.0 requires botocore>=1.24.7, but you have botocore 1.20.112 which is incompatible.\n",
      "awscli 1.25.27 requires botocore==1.27.27, but you have botocore 1.20.112 which is incompatible.\n",
      "awscli 1.25.27 requires rsa<4.8,>=3.1.2, but you have rsa 4.8 which is incompatible.\n",
      "awscli 1.25.27 requires s3transfer<0.7.0,>=0.6.0, but you have s3transfer 0.4.2 which is incompatible.\n",
      "aiobotocore 2.3.4 requires botocore<1.24.22,>=1.24.21, but you have botocore 1.20.112 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python -m pip install -Uq pip\n",
    "!python -m pip install -q awswrangler==2.2.0 imbalanced-learn==0.7.0 sagemaker==2.41.0 boto3==1.17.70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import boto3\n",
    "import string\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import awswrangler as wr\n",
    "\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeiros passos: criando recursos\n",
    "----\n",
    "Para executar este notebook com sucesso, você precisará criar alguns recursos da AWS.\n",
    "Primeiro, um bucket do S3 será criado para armazenar todos os dados deste tutorial.\n",
    "Depois de criado, você precisará criar uma função do AWS Glue usando o console do IAM e anexar uma política ao bucket do S3 para permitir o acesso do FeatureStore a este notebook. Se você já executou este notebook e está retomando de onde parou, a execução das células abaixo deve retomar os recursos que você já criou sem criar recursos adicionais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adicione a política FeatureStore à função de execução do Studio\n",
    "\n",
    "![title](images/iam-policies.png)\n",
    "\n",
    "\n",
    "1. Em uma guia separada do navegador, vá para a seção IAM do Console AWS\n",
    "2. Navegue até a seção Funções e selecione a função de execução que você está usando para o usuário do SageMaker Studio\n",
    "     * Se você não tiver certeza de qual função está usando, execute a célula abaixo para imprimi-la\n",
    "3. Anexe a política <font color='green'> AmazonSageMakerFeatureStoreAccess </font> a essa função. Uma vez anexado, as alterações entram em vigor imediatamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker Role: AmazonSageMaker-ExecutionRole-20220729T115042\n"
     ]
    }
   ],
   "source": [
    "print(\"SageMaker Role:\", sagemaker.get_execution_role().split(\"/\")[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecione a região, boto3 e SageMaker SDK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using AWS Region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "# You can change this to a region of your choice\n",
    "import sagemaker\n",
    "\n",
    "region = sagemaker.Session().boto_region_name\n",
    "print(\"Using AWS Region: {}\".format(region))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.setup_default_session(region_name=region)\n",
    "\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "s3_client = boto3.client(\"s3\", region_name=region)\n",
    "\n",
    "sagemaker_boto_client = boto_session.client(\"sagemaker\")\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session(\n",
    "    boto_session=boto_session, sagemaker_client=sagemaker_boto_client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Note: if you are not running this notebook from SageMaker Studio or SageMaker Classic Notebooks you will need to instanatiate \n",
    "the sagemaker_execution_role_name with an AWS role that has SageMakerFullAccess and SageMakerFeatureStoreFullAccess\n",
    "\"\"\"\n",
    "sagemaker_execution_role_name = \"AmazonSageMaker-ExecutionRole-20210107T234882\"\n",
    "try:\n",
    "    sagemaker_role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client(\"iam\")\n",
    "    sagemaker_role = iam.get_role(RoleName=sagemaker_execution_role_name)[\"Role\"][\"Arn\"]\n",
    "    print(f\"\\n instantiating sagemaker_role with supplied role name : {sagemaker_role}\")\n",
    "\n",
    "account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crie um diretório no bucket padrão do SageMaker para este tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'bucket' (str)\n",
      "Stored 'prefix' (str)\n",
      "Creating bucket: sagemaker-us-east-1-173965381620...\n"
     ]
    }
   ],
   "source": [
    "if \"bucket\" not in locals():\n",
    "    bucket = sagemaker_session.default_bucket()\n",
    "    prefix = \"fraud-detect-demo\"\n",
    "    %store bucket\n",
    "    %store prefix\n",
    "    print(f\"Creating bucket: {bucket}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se você quiser usar seu próprio bucket do S3 que já existe, remova o comentário e utilize o código de exemplo a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntry:\\n    s3_client.create_bucket(Bucket=bucket, ACL='private', CreateBucketConfiguration={'LocationConstraint': region})\\n    print('Create S3 bucket: SUCCESS')\\n    \\nexcept Exception as e:\\n    if e.response['Error']['Code'] == 'BucketAlreadyOwnedByYou':\\n        print(f'Using existing bucket: {bucket}/{prefix}')\\n    else:\\n        raise(e)\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "try:\n",
    "    s3_client.create_bucket(Bucket=bucket, ACL='private', CreateBucketConfiguration={'LocationConstraint': region})\n",
    "    print('Create S3 bucket: SUCCESS')\n",
    "    \n",
    "except Exception as e:\n",
    "    if e.response['Error']['Code'] == 'BucketAlreadyOwnedByYou':\n",
    "        print(f'Using existing bucket: {bucket}/{prefix}')\n",
    "    else:\n",
    "        raise(e)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======> Tons of output_paths\n",
    "traing_job_output_path = f\"s3://{bucket}/{prefix}/training_jobs\"\n",
    "bias_report_1_output_path = f\"s3://{bucket}/{prefix}/clarify-bias-1\"\n",
    "bias_report_2_output_path = f\"s3://{bucket}/{prefix}/clarify-bias-2\"\n",
    "explainability_output_path = f\"s3://{bucket}/{prefix}/clarify-explainability\"\n",
    "\n",
    "train_data_uri = f\"s3://{bucket}/{prefix}/data/train/train.csv\"\n",
    "test_data_uri = f\"s3://{bucket}/{prefix}/data/test/test.csv\"\n",
    "\n",
    "# =======> variables used for parameterizing the notebook run\n",
    "train_instance_count = 1\n",
    "train_instance_type = \"ml.m4.xlarge\"\n",
    "\n",
    "claify_instance_count = 1\n",
    "clairfy_instance_type = \"ml.c5.xlarge\"\n",
    "\n",
    "predictor_instance_count = 1\n",
    "predictor_instance_type = \"ml.c5.xlarge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregar dados brutos para o S3\n",
    "Antes que você possa pré-processar os dados brutos com o Data Wrangler, eles devem existir no S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.upload_file(\n",
    "    Filename=\"data/claims.csv\", Bucket=bucket, Key=f\"{prefix}/data/raw/claims.csv\"\n",
    ")\n",
    "s3_client.upload_file(\n",
    "    Filename=\"data/customers.csv\", Bucket=bucket, Key=f\"{prefix}/data/raw/customers.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atualizar atributos dentro do arquivo `.flow`\n",
    "O DataWrangler irá gerar um arquivo .flow. Ele contém uma referência a um bucket do S3 usado durante a Wrangling. Isso pode ser diferente daquele que você tem como padrão neste notebook, por exemplo, se o Wrangling foi feito por outra pessoa, você provavelmente não terá acesso ao seu bucket e agora você precisa apontar para seu próprio bucket do S3 para que você possa realmente carregar o arquivo .flow no Wrangler ou acesse os dados.\n",
    "\n",
    "Depois de executar a célula abaixo, você pode abrir os arquivos `claims.flow` e `customers.flow` e exportar os dados para o S3 ou pode continuar o guia usando os arquivos `data/claims_preprocessed.csv` e `data/customers_preprocessed.csv fornecidos ` arquivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_flow_template_file = \"claims_flow_template\"\n",
    "\n",
    "with open(claims_flow_template_file, \"r\") as f:\n",
    "    variables = {\"bucket\": bucket, \"prefix\": prefix}\n",
    "    template = string.Template(f.read())\n",
    "    claims_flow = template.substitute(variables)\n",
    "    claims_flow = json.loads(claims_flow)\n",
    "\n",
    "with open(\"claims.flow\", \"w\") as f:\n",
    "    json.dump(claims_flow, f)\n",
    "\n",
    "customers_flow_template_file = \"customers_flow_template\"\n",
    "\n",
    "with open(customers_flow_template_file, \"r\") as f:\n",
    "    variables = {\"bucket\": bucket, \"prefix\": prefix}\n",
    "    template = string.Template(f.read())\n",
    "    customers_flow = template.substitute(variables)\n",
    "    customers_flow = json.loads(customers_flow)\n",
    "\n",
    "with open(\"customers.flow\", \"w\") as f:\n",
    "    json.dump(customers_flow, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregar dados pré-processados do trabalho do Data Wrangler\n",
    "Se você executou as tarefas do Data Wrangler de `claims.flow` e `customers.flow`, você pode carregar seus dados pré-processados aqui. Se você não executou o trabalho do Data Wrangler, você ainda pode começar carregando os conjuntos de dados pré-fabricados do diretório `/data` deste exemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjuntos de dados e tipos de recursos\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_dtypes = {\n",
    "    \"policy_id\": int,\n",
    "    \"incident_severity\": int,\n",
    "    \"num_vehicles_involved\": int,\n",
    "    \"num_injuries\": int,\n",
    "    \"num_witnesses\": int,\n",
    "    \"police_report_available\": int,\n",
    "    \"injury_claim\": float,\n",
    "    \"vehicle_claim\": float,\n",
    "    \"total_claim_amount\": float,\n",
    "    \"incident_month\": int,\n",
    "    \"incident_day\": int,\n",
    "    \"incident_dow\": int,\n",
    "    \"incident_hour\": int,\n",
    "    \"fraud\": int,\n",
    "    \"driver_relationship_self\": int,\n",
    "    \"driver_relationship_na\": int,\n",
    "    \"driver_relationship_spouse\": int,\n",
    "    \"driver_relationship_child\": int,\n",
    "    \"driver_relationship_other\": int,\n",
    "    \"incident_type_collision\": int,\n",
    "    \"incident_type_breakin\": int,\n",
    "    \"incident_type_theft\": int,\n",
    "    \"collision_type_front\": int,\n",
    "    \"collision_type_rear\": int,\n",
    "    \"collision_type_side\": int,\n",
    "    \"collision_type_na\": int,\n",
    "    \"authorities_contacted_police\": int,\n",
    "    \"authorities_contacted_none\": int,\n",
    "    \"authorities_contacted_fire\": int,\n",
    "    \"authorities_contacted_ambulance\": int,\n",
    "    \"event_time\": float,\n",
    "}\n",
    "\n",
    "customers_dtypes = {\n",
    "    \"policy_id\": int,\n",
    "    \"customer_age\": int,\n",
    "    \"customer_education\": int,\n",
    "    \"months_as_customer\": int,\n",
    "    \"policy_deductable\": int,\n",
    "    \"policy_annual_premium\": int,\n",
    "    \"policy_liability\": int,\n",
    "    \"auto_year\": int,\n",
    "    \"num_claims_past_year\": int,\n",
    "    \"num_insurers_past_5_years\": int,\n",
    "    \"customer_gender_male\": int,\n",
    "    \"customer_gender_female\": int,\n",
    "    \"policy_state_ca\": int,\n",
    "    \"policy_state_wa\": int,\n",
    "    \"policy_state_az\": int,\n",
    "    \"policy_state_or\": int,\n",
    "    \"policy_state_nv\": int,\n",
    "    \"policy_state_id\": int,\n",
    "    \"event_time\": float,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to load Data Wrangler output. Loading pre-made dataframes...\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# ======> This is your DataFlow output path if you decide to redo the work in DataFlow on your own\n",
    "# flow_output_path = <YOUR_PATH_HERE>\n",
    "claims_flow_path = \"\"\n",
    "customers_flow_path = \"\"\n",
    "\n",
    "try:\n",
    "    # this will try to load the exported dataframes from the claims and customers .flow files\n",
    "    claims_s3_path = f\"{flow_output_path}/claims_output\"\n",
    "    customers_s3_path = f\"{flow_output_path}/customers_output\"\n",
    "\n",
    "    claims_preprocessed = wr.s3.read_csv(path=claims_s3_path, dataset=True, dtype=claims_dtypes)\n",
    "\n",
    "    customers_preprocessed = wr.s3.read_csv(\n",
    "        path=customers_s3_path, dataset=True, dtype=customers_dtypes\n",
    "    )\n",
    "\n",
    "except:\n",
    "    # if the Data Wrangler job was not run, the claims and customers dataframes will be loaded from local copies\n",
    "    timestamp = pd.to_datetime(\"now\").timestamp()\n",
    "    print(\"Unable to load Data Wrangler output. Loading pre-made dataframes...\")\n",
    "\n",
    "    claims_preprocessed = pd.read_csv(\n",
    "        filepath_or_buffer=\"data/claims_preprocessed.csv\", dtype=claims_dtypes\n",
    "    )\n",
    "\n",
    "    # a timestamp column is required by the feature store, so one is added with a current timestamp\n",
    "    claims_preprocessed[\"event_time\"] = timestamp\n",
    "\n",
    "    customers_preprocessed = pd.read_csv(\n",
    "        filepath_or_buffer=\"data/customers_preprocessed.csv\", dtype=customers_dtypes\n",
    "    )\n",
    "\n",
    "    customers_preprocessed[\"event_time\"] = timestamp\n",
    "\n",
    "    print(\"Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora temos um conjunto de DataFrames do Pandas que contém os dados do cliente e da reclamação, com os tipos de dados corretos. Quando o Dat Wrangler codifica um recurso como um recurso de codificação única, ele usará como padrão os tipos de dados flutuantes para esses recursos resultantes (um recurso --> muitas colunas para a codificação a quente).\n",
    "\n",
    "<font color ='red'> Nota: </font> a razão para converter explicitamente os tipos de dados para recursos categóricos gerados pelo Data Wrangler é garantir que eles sejam do tipo inteiro para que o Clarify os trate como variáveis categóricas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Armazenamento de recursos do SageMaker\n",
    "----\n",
    "\n",
    "O Amazon SageMaker Feature Store é um repositório criado especificamente para você armazenar e acessar recursos para que seja muito mais fácil nomeá-los, organizá-los e reutilizá-los entre as equipes. O SageMaker Feature Store fornece um armazenamento unificado de recursos durante o treinamento e inferência em tempo real sem a necessidade de escrever código adicional ou criar processos manuais para manter os recursos consistentes. O SageMaker Feature Store acompanha os metadados dos recursos armazenados (por exemplo, nome do recurso ou número da versão) para que você possa consultar os recursos para os atributos certos em lotes ou em tempo real usando o Amazon Athena, um serviço de consulta interativa. O SageMaker Feature Store também mantém os recursos atualizados, pois à medida que novos dados são gerados durante a inferência, o repositório único é atualizado para que novos recursos estejam sempre disponíveis para os modelos usarem durante o treinamento e a inferência.\n",
    "\n",
    "Um repositório de recursos consiste em um componente offline armazenado no S3 e um componente online armazenado em um banco de dados de baixa latência. O banco de dados online é opcional, mas muito útil se você precisar que recursos suplementares estejam disponíveis na inferência. Nesta seção, criaremos grupos de recursos para nossos conjuntos de dados de Reclamações e Clientes. Depois de inserir as declarações e os dados do cliente em seus respectivos grupos de recursos, você precisa consultar a armazenamento offline com o Athena para criar o conjunto de dados de treinamento.\n",
    "\n",
    "Você pode consultar o [Guia do desenvolvedor do SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/feature-store.html) para obter mais informações sobre o SageMaker Feature Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurestore_runtime = boto_session.client(\n",
    "    service_name=\"sagemaker-featurestore-runtime\", region_name=region\n",
    ")\n",
    "\n",
    "feature_store_session = sagemaker.Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_boto_client,\n",
    "    sagemaker_featurestore_runtime_client=featurestore_runtime,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure os grupos de recursos\n",
    "O tipo de dados para cada recurso é definido passando um dataframe e inferindo o tipo de dados apropriado. Os tipos de dados de recursos também podem ser definidos por meio de uma variável de configuração, mas terão que corresponder ao tipo de dados Python correspondente no dataframe do Pandas quando forem ingeridos no Grupo de recursos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'claims_fg_name' (str)\n",
      "Stored 'customers_fg_name' (str)\n"
     ]
    }
   ],
   "source": [
    "claims_fg_name = f\"{prefix}-claims\"\n",
    "customers_fg_name = f\"{prefix}-customers\"\n",
    "%store claims_fg_name\n",
    "%store customers_fg_name\n",
    "\n",
    "claims_feature_group = FeatureGroup(name=claims_fg_name, sagemaker_session=feature_store_session)\n",
    "\n",
    "customers_feature_group = FeatureGroup(\n",
    "    name=customers_fg_name, sagemaker_session=feature_store_session\n",
    ")\n",
    "\n",
    "claims_feature_group.load_feature_definitions(data_frame=claims_preprocessed)\n",
    "customers_feature_group.load_feature_definitions(data_frame=customers_preprocessed);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crie os grupos de recursos\n",
    "Você deve informar ao Feature Group quais colunas no dataframe correspondem ao identificador de registro necessário e aos recursos de tempo do evento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraud-detect-demo-customers -- fraud-detect-demo-claims are the feature group names in use\n"
     ]
    }
   ],
   "source": [
    "print(f\"{customers_fg_name} -- {claims_fg_name} are the feature group names in use\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Using s3://sagemaker-us-east-1-173965381620/fraud-detect-demo\n",
      "Create \"claims\" feature group: SUCCESS\n",
      "Create \"customers\" feature group: SUCCESS\n"
     ]
    }
   ],
   "source": [
    "record_identifier_feature_name = \"policy_id\"\n",
    "event_time_feature_name = \"event_time\"\n",
    "\n",
    "try:\n",
    "    print(f\"\\n Using s3://{bucket}/{prefix}\")\n",
    "    claims_feature_group.create(\n",
    "        s3_uri=f\"s3://{bucket}/{prefix}\",\n",
    "        record_identifier_name=record_identifier_feature_name,\n",
    "        event_time_feature_name=event_time_feature_name,\n",
    "        role_arn=sagemaker_role,\n",
    "        enable_online_store=True,\n",
    "    )\n",
    "    print(f'Create \"claims\" feature group: SUCCESS')\n",
    "except Exception as e:\n",
    "    code = e.response.get(\"Error\").get(\"Code\")\n",
    "    if code == \"ResourceInUse\":\n",
    "        print(f\"Using existing feature group: {claims_fg_name}\")\n",
    "    else:\n",
    "        raise (e)\n",
    "\n",
    "try:\n",
    "    customers_feature_group.create(\n",
    "        s3_uri=f\"s3://{bucket}/{prefix}\",\n",
    "        record_identifier_name=record_identifier_feature_name,\n",
    "        event_time_feature_name=event_time_feature_name,\n",
    "        role_arn=sagemaker_role,\n",
    "        enable_online_store=True,\n",
    "    )\n",
    "    print(f'Create \"customers\" feature group: SUCCESS')\n",
    "except Exception as e:\n",
    "    code = e.response.get(\"Error\").get(\"Code\")\n",
    "    if code == \"ResourceInUse\":\n",
    "        print(f\"Using existing feature group: {customers_fg_name}\")\n",
    "    else:\n",
    "        raise (e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aguarde até que a criação do grupo de recursos seja totalmente concluída"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for Feature Group Creation\n",
      "Waiting for Feature Group Creation\n",
      "Waiting for Feature Group Creation\n",
      "FeatureGroup fraud-detect-demo-claims successfully created.\n",
      "Waiting for Feature Group Creation\n",
      "FeatureGroup fraud-detect-demo-customers successfully created.\n"
     ]
    }
   ],
   "source": [
    "def wait_for_feature_group_creation_complete(feature_group):\n",
    "    status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "    while status == \"Creating\":\n",
    "        print(\"Waiting for Feature Group Creation\")\n",
    "        time.sleep(5)\n",
    "        status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "    if status != \"Created\":\n",
    "        raise RuntimeError(f\"Failed to create feature group {feature_group.name}\")\n",
    "    print(f\"FeatureGroup {feature_group.name} successfully created.\")\n",
    "\n",
    "\n",
    "wait_for_feature_group_creation_complete(feature_group=claims_feature_group)\n",
    "wait_for_feature_group_creation_complete(feature_group=customers_feature_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingerir registros nos grupos de recursos\n",
    "Após a criação dos grupos de recursos, podemos colocar dados em cada armazenamento usando a API PutRecord. Essa API pode lidar com TPS alto e foi projetada para ser chamada por diferentes fluxos. Os dados de todas essas solicitações Put são armazenados em buffer e gravados em s3 em partes. Os arquivos serão gravados no armazenamento offline alguns minutos após a ingestão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"claims_table\" in locals():\n",
    "    print(\n",
    "        \"You may have already ingested the data into your Feature Groups. If you'd like to do this again, you can run the ingest methods outside of the 'if/else' statement.\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    claims_feature_group.ingest(data_frame=claims_preprocessed, max_workers=3, wait=True)\n",
    "\n",
    "    customers_feature_group.ingest(data_frame=customers_preprocessed, max_workers=3, wait=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aguarde até que os dados de armazenamento offline fiquem disponíveis\n",
    "Isso geralmente leva de 5 a 8 minutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraud-detect-demo/173965381620/sagemaker/us-east-1/offline-store/fraud-detect-demo-claims-1661685235/data\n",
      "Waiting for data in offline store...\n",
      "Waiting for data in offline store...\n",
      "Waiting for data in offline store...\n",
      "Waiting for data in offline store...\n",
      "Waiting for data in offline store...\n",
      "\n",
      "Data available.\n"
     ]
    }
   ],
   "source": [
    "if \"claims_table\" not in locals():\n",
    "    claims_table = claims_feature_group.describe()[\"OfflineStoreConfig\"][\"DataCatalogConfig\"][\n",
    "        \"TableName\"\n",
    "    ]\n",
    "if \"customers_table\" not in locals():\n",
    "    customers_table = customers_feature_group.describe()[\"OfflineStoreConfig\"][\"DataCatalogConfig\"][\n",
    "        \"TableName\"\n",
    "    ]\n",
    "\n",
    "claims_feature_group_s3_prefix = (\n",
    "    f\"{prefix}/{account_id}/sagemaker/{region}/offline-store/{claims_table}/data\"\n",
    ")\n",
    "customers_feature_group_s3_prefix = (\n",
    "    f\"{prefix}/{account_id}/sagemaker/{region}/offline-store/{customers_table}/data\"\n",
    ")\n",
    "\n",
    "print(claims_feature_group_s3_prefix)\n",
    "\n",
    "offline_store_contents = None\n",
    "while offline_store_contents is None:\n",
    "    objects_in_bucket = s3_client.list_objects(\n",
    "        Bucket=bucket, Prefix=customers_feature_group_s3_prefix\n",
    "    )\n",
    "    if \"Contents\" in objects_in_bucket and len(objects_in_bucket[\"Contents\"]) > 1:\n",
    "        offline_store_contents = objects_in_bucket[\"Contents\"]\n",
    "    else:\n",
    "        print(\"Waiting for data in offline store...\")\n",
    "        time.sleep(60)\n",
    "\n",
    "print(\"\\nData available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'TableName': 'fraud-detect-demo-claims-1661685235',\n",
       "  'Catalog': 'AwsDataCatalog',\n",
       "  'Database': 'sagemaker_featurestore'},\n",
       " {'TableName': 'fraud-detect-demo-customers-1661685237',\n",
       "  'Catalog': 'AwsDataCatalog',\n",
       "  'Database': 'sagemaker_featurestore'})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claims_feature_group.describe()[\"OfflineStoreConfig\"][\n",
    "    \"DataCatalogConfig\"\n",
    "], customers_feature_group.describe()[\"OfflineStoreConfig\"][\"DataCatalogConfig\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crie conjuntos de dados de treinamento e teste\n",
    "----\n",
    "\n",
    "Assim que os dados estiverem disponíveis no armazenamento offline, eles serão automaticamente catalogados e carregados em uma tabela do Athena (isso é feito por padrão, mas pode ser desativado). Para construir nossos conjuntos de dados de treinamento e teste, você enviará uma consulta SQL para unir as tabelas Claims e Customers criadas no Athena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'claims_table' (str)\n",
      "Stored 'customers_table' (str)\n",
      "Stored 'database_name' (str)\n"
     ]
    }
   ],
   "source": [
    "claims_query = claims_feature_group.athena_query()\n",
    "customers_query = customers_feature_group.athena_query()\n",
    "\n",
    "claims_table = claims_query.table_name\n",
    "customers_table = customers_query.table_name\n",
    "database_name = customers_query.database\n",
    "%store claims_table\n",
    "%store customers_table\n",
    "%store database_name\n",
    "\n",
    "feature_columns = list(set(claims_preprocessed.columns) ^ set(customers_preprocessed.columns))\n",
    "feature_columns_string = \", \".join(f'\"{c}\"' for c in feature_columns)\n",
    "feature_columns_string = f'\"{claims_table}\".policy_id as policy_id, ' + feature_columns_string\n",
    "\n",
    "query_string = f\"\"\"\n",
    "SELECT DISTINCT {feature_columns_string}\n",
    "FROM \"{claims_table}\" LEFT JOIN \"{customers_table}\" \n",
    "ON \"{claims_table}\".policy_id = \"{customers_table}\".policy_id\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_query.run(query_string=query_string, output_location=f\"s3://{bucket}/{prefix}/query_results\")\n",
    "claims_query.wait()\n",
    "dataset = claims_query.as_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"./data/claims_customer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_order = [\"fraud\"] + list(dataset.drop([\"fraud\", \"policy_id\"], axis=1).columns)\n",
    "\n",
    "train = dataset.sample(frac=0.80, random_state=0)[col_order]\n",
    "test = dataset.drop(train.index)[col_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gravar treino, testar dados para S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"data/train.csv\", index=False)\n",
    "test.to_csv(\"data/test.csv\", index=False)\n",
    "dataset.to_csv(\"data/dataset.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fraud</th>\n",
       "      <th>collision_type_rear</th>\n",
       "      <th>customer_age</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>incident_severity</th>\n",
       "      <th>authorities_contacted_ambulance</th>\n",
       "      <th>policy_liability</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>auto_year</th>\n",
       "      <th>num_injuries</th>\n",
       "      <th>...</th>\n",
       "      <th>incident_day</th>\n",
       "      <th>injury_claim</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>authorities_contacted_fire</th>\n",
       "      <th>police_report_available</th>\n",
       "      <th>customer_gender_male</th>\n",
       "      <th>policy_state_az</th>\n",
       "      <th>policy_state_nv</th>\n",
       "      <th>authorities_contacted_none</th>\n",
       "      <th>policy_state_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3833</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>9500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9500.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>750</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4836</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4572</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>17500.0</td>\n",
       "      <td>750</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>38000.0</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>750</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fraud  collision_type_rear  customer_age  vehicle_claim  \\\n",
       "398       1                    1            57         6000.0   \n",
       "3833      0                    0            19         9500.0   \n",
       "4836      0                    0            39        10000.0   \n",
       "4572      0                    1            49        32000.0   \n",
       "636       0                    0            57         8000.0   \n",
       "\n",
       "      incident_severity  authorities_contacted_ambulance  policy_liability  \\\n",
       "398                   0                                0                 0   \n",
       "3833                  0                                0                 1   \n",
       "4836                  0                                0                 0   \n",
       "4572                  2                                0                 2   \n",
       "636                   1                                0                 2   \n",
       "\n",
       "      total_claim_amount  auto_year  num_injuries  ...  incident_day  \\\n",
       "398               6000.0       2017             0  ...             2   \n",
       "3833              9500.0       2016             0  ...             5   \n",
       "4836             10000.0       2019             0  ...             8   \n",
       "4572             49500.0       2012             1  ...             9   \n",
       "636              38000.0       2005             1  ...            29   \n",
       "\n",
       "      injury_claim  policy_deductable  authorities_contacted_fire  \\\n",
       "398            0.0                750                           0   \n",
       "3833           0.0                750                           0   \n",
       "4836           0.0                750                           0   \n",
       "4572       17500.0                750                           0   \n",
       "636        30000.0                750                           0   \n",
       "\n",
       "      police_report_available  customer_gender_male  policy_state_az  \\\n",
       "398                         0                     1                0   \n",
       "3833                        1                     1                0   \n",
       "4836                        0                     1                0   \n",
       "4572                        1                     0                0   \n",
       "636                         1                     0                0   \n",
       "\n",
       "      policy_state_nv  authorities_contacted_none  policy_state_id  \n",
       "398                 0                           1                0  \n",
       "3833                0                           0                0  \n",
       "4836                0                           0                0  \n",
       "4572                0                           0                1  \n",
       "636                 0                           0                0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fraud</th>\n",
       "      <th>collision_type_rear</th>\n",
       "      <th>customer_age</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>incident_severity</th>\n",
       "      <th>authorities_contacted_ambulance</th>\n",
       "      <th>policy_liability</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>auto_year</th>\n",
       "      <th>num_injuries</th>\n",
       "      <th>...</th>\n",
       "      <th>incident_day</th>\n",
       "      <th>injury_claim</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>authorities_contacted_fire</th>\n",
       "      <th>police_report_available</th>\n",
       "      <th>customer_gender_male</th>\n",
       "      <th>policy_state_az</th>\n",
       "      <th>policy_state_nv</th>\n",
       "      <th>authorities_contacted_none</th>\n",
       "      <th>policy_state_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>15500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15500.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>750</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>15500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15500.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>9500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9500.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    fraud  collision_type_rear  customer_age  vehicle_claim  \\\n",
       "0       0                    0            30        15500.0   \n",
       "7       0                    0            38         7500.0   \n",
       "21      0                    1            53        28000.0   \n",
       "24      0                    0            39        15500.0   \n",
       "25      0                    0            41         9500.0   \n",
       "\n",
       "    incident_severity  authorities_contacted_ambulance  policy_liability  \\\n",
       "0                   0                                0                 1   \n",
       "7                   0                                0                 1   \n",
       "21                  2                                0                 2   \n",
       "24                  1                                0                 2   \n",
       "25                  0                                0                 1   \n",
       "\n",
       "    total_claim_amount  auto_year  num_injuries  ...  incident_day  \\\n",
       "0              15500.0       2019             0  ...            31   \n",
       "7               7500.0       2012             0  ...            23   \n",
       "21             28000.0       2016             0  ...             8   \n",
       "24             15500.0       2019             0  ...            15   \n",
       "25              9500.0       2020             0  ...            30   \n",
       "\n",
       "    injury_claim  policy_deductable  authorities_contacted_fire  \\\n",
       "0            0.0                750                           0   \n",
       "7            0.0                750                           0   \n",
       "21           0.0                750                           0   \n",
       "24           0.0                750                           0   \n",
       "25           0.0                750                           0   \n",
       "\n",
       "    police_report_available  customer_gender_male  policy_state_az  \\\n",
       "0                         0                     1                0   \n",
       "7                         0                     1                0   \n",
       "21                        1                     1                0   \n",
       "24                        0                     0                0   \n",
       "25                        0                     1                0   \n",
       "\n",
       "    policy_state_nv  authorities_contacted_none  policy_state_id  \n",
       "0                 0                           0                0  \n",
       "7                 0                           0                0  \n",
       "21                0                           0                0  \n",
       "24                0                           0                0  \n",
       "25                0                           0                0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
